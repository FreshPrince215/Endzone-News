# ğŸˆ NFL News Aggregator

A professional, real-time news aggregation platform that consolidates NFL news from 10+ major sports media sources into a single, streamlined interface. Built with Python and Streamlit, featuring dark/light mode themes and advanced filtering capabilities.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## ğŸ¯ Project Overview

This application solves the problem of information overload in sports news by aggregating content from multiple sources, intelligently categorizing it by team, and presenting it in a clean, filterable interface. 

## âœ¨ Key Features

### ğŸ“° Multi-Source Aggregation
- **10+ News Sources**: ESPN, NFL.com, Yahoo Sports, CBS Sports, The Athletic, NBC Sports, Fox Sports, Bleacher Report, USA Today, and more
- **32 Team-Specific Feeds**: Direct feeds from official team websites and trusted team blogs
- **Real-Time Updates**: Automatic content refresh every 30 minutes with smart caching
- **80+ RSS Feeds**: Comprehensive coverage across the entire NFL landscape

### ğŸ¨ Modern User Interface
- **Dark/Light Mode**: Seamless theme switching for comfortable viewing at any time
- **Responsive Design**: Works perfectly on desktop, tablet, and mobile devices
- **Live Status Indicator**: Real-time updates showing when data was last refreshed
- **Smooth Animations**: Professional transitions and hover effects

### ğŸ” Advanced Filtering & Sorting
- **Team Filter**: Focus on specific teams or view league-wide news
- **Sorting Options**: View articles by newest or oldest first
- **Smart Search**: Automatic team detection from article headlines

### ğŸ“Š Analytics Dashboard
- **Total Articles**: Track the volume of news coverage at a glance

### ğŸš€ Performance Optimization
- **Parallel Processing**: Concurrent feed fetching using ThreadPoolExecutor
- **Smart Caching**: 30-minute TTL to reduce API calls and improve load times
- **Content Deduplication**: MD5 hashing to eliminate duplicate articles
- **Error Handling**: Robust exception handling for unreliable RSS feeds

## ğŸ› ï¸ Technical Architecture

### Core Technologies
- **Python 3.8+**: Primary programming language
- **Streamlit**: Web application framework
- **Feedparser**: RSS/Atom feed parsing
- **Pandas**: Data manipulation and analysis
- **ThreadPoolExecutor**: Parallel RSS feed fetching

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Interface Layer                     â”‚
â”‚                    (Streamlit Frontend)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Application Logic Layer                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Theme      â”‚  â”‚   Filter     â”‚  â”‚   Metrics    â”‚     â”‚
â”‚  â”‚  Management  â”‚  â”‚   Engine     â”‚  â”‚  Calculator  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Processing Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Content    â”‚  â”‚     Team     â”‚  â”‚     Data     â”‚     â”‚
â”‚  â”‚    Parser    â”‚  â”‚  Detection   â”‚  â”‚ Deduplicationâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Data Fetching Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚      RSSFeedFetcher (ThreadPoolExecutor)         â”‚      â”‚
â”‚  â”‚  - Parallel feed fetching (10 workers)           â”‚      â”‚
â”‚  â”‚  - Error handling & retry logic                  â”‚      â”‚
â”‚  â”‚  - User-agent rotation                           â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Data Sources                     â”‚
â”‚   ESPN â”‚ NFL.com â”‚ Yahoo â”‚ CBS â”‚ The Athletic â”‚ ...         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Configuration Loading**: Application reads `config.json` with feed URLs and settings
2. **Parallel Feed Fetching**: ThreadPoolExecutor fetches multiple RSS feeds simultaneously
3. **Content Parsing**: Feedparser extracts article metadata (title, link, date, summary)
4. **HTML Sanitization**: Remove HTML tags and clean text content
5. **Team Detection**: Intelligent keyword matching to identify relevant teams
6. **Deduplication**: MD5 hashing eliminates duplicate articles across sources
7. **Caching**: Streamlit's @st.cache_data stores results for 30 minutes
8. **Filtering & Sorting**: Real-time data manipulation based on user selections
9. **Rendering**: Dynamic HTML generation with theme-aware CSS

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager
- Internet connection for RSS feeds

### Step-by-Step Setup

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/nfl-news-aggregator.git
cd nfl-news-aggregator
```

2. **Create a virtual environment** (recommended)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install streamlit feedparser pandas
```

Or use requirements.txt:
```bash
pip install -r requirements.txt
```

4. **Verify file structure**
```
nfl-news-aggregator/
â”œâ”€â”€ app.py              # Main application file
â”œâ”€â”€ config.json         # Configuration and RSS feeds
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md          # This file
```

5. **Run the application**
```bash
streamlit run app.py
```

6. **Access the application**
Open your web browser and navigate to:
```
http://localhost:8501
```

## âš™ï¸ Configuration

The `config.json` file controls all application settings and data sources.

### Application Settings

```json
{
  "app": {
    "title": "NFL News Aggregator",
    "page_icon": "ğŸˆ",
    "cache_ttl": 1800,        // Cache duration in seconds (30 min)
    "days_lookback": 7,        // How many days of news to fetch
    "max_workers": 10          // Parallel thread pool size
  }
}
```

### Adding Custom RSS Feeds

**General News Source:**
```json
{
  "name": "Your Source Name",
  "url": "https://example.com/rss/feed",
  "enabled": true
}
```

**Team-Specific Feed:**
```json
{
  "Dallas Cowboys": [
    "https://www.dallascowboys.com/rss/news",
    "https://custom-cowboys-blog.com/feed"
  ]
}
```

### Customization Options

| Setting | Description | Default |
|---------|-------------|---------|
| `cache_ttl` | How long to cache data (seconds) | 1800 (30 min) |
| `days_lookback` | Number of days of historical news | 7 |
| `max_workers` | Parallel thread pool size | 10 |
| `enabled` | Enable/disable specific feeds | true |

## ğŸ¨ Usage Guide

### Basic Navigation

1. **View All News**: Default view shows all articles from all teams
2. **Filter by Team**: Select a specific team from the dropdown to see team-specific news
3. **Sort Articles**: Toggle between newest/oldest first
4. **Toggle Theme**: Click the theme button to switch between dark/light modes

### Advanced Tips

- **Fresh Data**: The app auto-refreshes every 30 minutes, or manually refresh the page
- **Article Summaries**: Hover over articles to see preview summaries
- **External Links**: Click any headline to read the full article on the source website
- **Performance**: The app caches data to load instantly on repeated visits

## ğŸ—ï¸ Code Structure

### Main Components

#### `app.py`
```python
# Configuration Management
load_application_config()     # Loads config.json settings

# Data Fetching
RSSFeedFetcher              # Handles parallel RSS feed fetching
â”œâ”€â”€ fetch_feed()            # Fetches single feed with error handling
â”œâ”€â”€ fetch_multiple_feeds()  # Parallel fetching with ThreadPoolExecutor
â””â”€â”€ sanitize_html_content() # Cleans HTML from summaries

# Data Processing
NewsDataProcessor           # Data cleaning and transformation
â”œâ”€â”€ generate_content_hash() # Creates MD5 hash for deduplication
â”œâ”€â”€ remove_duplicate_articles() # Eliminates duplicate content
â””â”€â”€ identify_team_from_content() # Intelligent team detection

# Caching
fetch_all_news_articles()   # Cached data fetching (30 min TTL)

# UI Components
apply_application_styles()  # Theme-aware CSS styling
render_application_header() # Header with live status
render_metrics_dashboard()  # Analytics dashboard
render_news_article()       # Individual article cards
```

### Design Patterns

- **Factory Pattern**: RSSFeedFetcher creates article objects
- **Strategy Pattern**: Different sorting and filtering strategies
- **Observer Pattern**: Streamlit's reactive data flow
- **Singleton Pattern**: Configuration loaded once and cached

### Performance Optimizations

1. **Parallel Processing**: 10 concurrent threads for feed fetching
2. **Smart Caching**: 30-minute TTL reduces redundant API calls
3. **Lazy Loading**: Data fetched only when needed
4. **Content Deduplication**: Eliminates duplicate processing
5. **HTML Sanitization**: Truncates summaries to 300 characters

## ğŸ“Š Features in Detail

### Intelligent Team Detection

The system uses a comprehensive keyword mapping to automatically categorize articles:

```python
team_keyword_mapping = {
    'RAVENS': 'Baltimore Ravens',
    'BILLS': 'Buffalo Bills',
    'CHIEFS': 'Kansas City Chiefs',
    # ... 32 teams total
}
```

When an article title contains "Ravens dominate Bengals", the system automatically tags it as Baltimore Ravens news.

### Content Deduplication

Articles from different sources often report the same news. The app uses MD5 hashing:

```python
def generate_content_hash(text: str) -> str:
    return hashlib.md5(text.encode()).hexdigest()
```

This ensures each unique story appears only once, even if published by multiple outlets.

### Parallel Feed Fetching

Instead of fetching feeds sequentially (slow), the app uses concurrent threads:

```python
with ThreadPoolExecutor(max_workers=10) as executor:
    futures = {executor.submit(fetch_feed, url, name) 
               for url, name in feeds}
```

This reduces total fetch time from ~30 seconds to ~3 seconds.

## ğŸ› Troubleshooting

### Common Issues

**Issue: "No news articles available"**
- **Cause**: RSS feeds are temporarily unavailable or blocked
- **Solution**: Check your internet connection, wait 5 minutes and refresh

**Issue: "Configuration file not found"**
- **Cause**: `config.json` is missing or in wrong directory
- **Solution**: Ensure `config.json` is in the same folder as `app.py`

**Issue: Slow loading times**
- **Cause**: Too many RSS feeds or slow network
- **Solution**: Reduce `max_workers` in config or disable some feeds

**Issue: Theme not switching**
- **Cause**: Browser cache issue
- **Solution**: Hard refresh (Ctrl+Shift+R on Windows/Linux, Cmd+Shift+R on Mac)

### Debug Mode

Enable Streamlit debug mode for detailed error messages:

```bash
streamlit run app.py --logger.level=debug
```

## ğŸš€ Deployment

### Streamlit Cloud (Free)

1. Push code to GitHub repository
2. Visit [share.streamlit.io](https://share.streamlit.io)
3. Connect your GitHub account
4. Select repository and branch
5. Click "Deploy"

### Heroku

```bash
# Create Procfile
echo "web: streamlit run app.py --server.port=$PORT" > Procfile

# Deploy
heroku create nfl-news-aggregator
git push heroku main
```

### Docker

```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8501
CMD ["streamlit", "run", "app.py"]
```



## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Your Name**
- LinkedIn: [your-linkedin-profile](https://linkedin.com/in/yourprofile)
- GitHub: [@yourusername](https://github.com/FreshPrince215)


## ğŸ™ Acknowledgments

- **Streamlit** - For the amazing web app framework
- **NFL Teams** - For providing official RSS feeds
- **Sports Media Outlets** - ESPN, Yahoo, CBS, NBC, Fox, and others
- **Open Source Community** - For the incredible Python ecosystem

## ğŸ“š Additional Resources

- [Streamlit Documentation](https://docs.streamlit.io/)
- [Feedparser Documentation](https://feedparser.readthedocs.io/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [NFL API Documentation](https://www.nfl.com/feeds/)

## ğŸ’¡ Project Showcase

This project demonstrates proficiency in:
- **Data Engineering**: RSS feed aggregation, ETL pipelines, data deduplication
- **Backend Development**: Python, parallel processing, caching strategies
- **Frontend Development**: Streamlit, responsive design, dark/light themes
- **Software Architecture**: Modular design, separation of concerns, scalability
- **DevOps**: Configuration management, error handling, deployment ready

Perfect for demonstrating full-stack capabilities to potential employers!

---
